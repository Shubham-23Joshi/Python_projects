{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fd95c5c-0057-4468-ba5d-de8945589fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.4.post1\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# ->\n",
    "import os\n",
    "import time\n",
    "import pygame\n",
    "import pygame.camera\n",
    "from pygame.locals import *\n",
    "import numpy as np\n",
    "from pycoral.utils import edgetpu\n",
    "from pycoral.utils import dataset\n",
    "from pycoral.adapters import common\n",
    "from pycoral.adapters import classify\n",
    "from PIL import Image\n",
    "from imutils.video import VideoStream\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4356e343-9769-475c-8c07-de155100493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ->\n",
    "# Specify the TensorFlow model, labels, and image\n",
    "#script_dir = pathlib.Path('/home/mendel').parent.absolute()\n",
    "model_file = 'handwriting_model2_quant_edgetpu.tflite'\n",
    "label_file = 'digits_labels.txt'\n",
    "#image_file = '2_img.GIF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53ad05fb-cdac-4722-857e-5047220769e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ->\n",
    "# Initialize the TF interpreter\n",
    "interpreter = edgetpu.make_interpreter(model_file)\n",
    "interpreter.allocate_tensors()\n",
    "size = common.input_size(interpreter)\n",
    "# extract labels\n",
    "labels = dataset.read_label_file(label_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7ecd931-7baf-4f9a-aca7-127254d18b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]0;caca for ncurses\u0007\u001b)0\u001b7\u001b[?47h\u001b[1;24r\u001b[m\u001b[4l\u001b[?1h\u001b=\u001b[?1000h\u001b[m\u001b[m\u001b[37m\u001b[40m\u001b[1;1H                                                                                \u001b[2;1H                                                                                \u001b[3;1H                                                                                \u001b[4;1H                                                                                \u001b[5;1H                                                                                \u001b[6;1H                                                                                \u001b[7;1H                                                                                \u001b[8;1H                                                                                \u001b[9;1H                                                                                \u001b[10;1H                                                                                \u001b[11;1H                                                                            Using camera:  /dev/video1\n",
      "    \u001b[12;1H                                                                                \u001b[13;1H                                                                                \u001b[14;1H                                                                                \u001b[15;1H                                                                                \u001b[16;1H                                                                                \u001b[17;1H                                                                                \u001b[18;1H                                                                                \u001b[19;1H                                                                                \u001b[20;1H                                                                                \u001b[21;1H                                                                                \u001b[22;1H                                                                                \u001b[23;1H                                                                                \u001b[24;1H                                                                              \u001b[4h \u001b[4l\u001b[H"
     ]
    }
   ],
   "source": [
    "# ->\n",
    "# initialize pygame and camera\n",
    "pygame.init()\n",
    "pygame.camera.init()\n",
    "camlist = pygame.camera.list_cameras()\n",
    "print('Using camera: ', camlist[-1])\n",
    "cam = pygame.camera.Camera(camlist[-1], (640, 480))\n",
    "cam.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1bfd07-172f-480a-9d88-22f44e918df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    while True:\n",
    "        # getting image frame from camera\n",
    "        surf_img_raw = cam.get_image()\n",
    "        surf_img = pygame.transform.scale(surf_img_raw, size)\n",
    "        \n",
    "        # image preprocessing\n",
    "        img = pygame.surfarray.array2d(surf_img) # converting to numpy array\n",
    "        img_pil = Image.fromarray(img)\n",
    "        img_arr = np.array(img_pil.convert('L').resize(size, Image.ANTIALIAS))\n",
    "        # broadcasting img_arr to fit dimentions (28, 28, 1)\n",
    "        img_arr = img_arr.reshape((28,28,1))\n",
    "        \n",
    "        # inferencing\n",
    "        interpreter.invoke()\n",
    "        common.set_input(interpreter, img_arr)\n",
    "        classes = classify.get_classes(interpreter, top_k=1)\n",
    "        print(classes)\n",
    "        time.sleep(1)\n",
    "        \n",
    "finally:\n",
    "    cam.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66e3cf0-9ac6-403e-99e0-199b9c10833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera streaming test\n",
    "frame = vs.read()\n",
    "frame = imutils.resize(frame, width=500)\n",
    "test = frame.copy()\n",
    "cv.imshow(\"Test Frame\", test)\n",
    "key = cv.waitKey(1) & 0xFF\n",
    "cv.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97c15710-fe5d-44e7-a58d-0dc75f220a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@386.662] global /io/opencv/modules/videoio/src/cap_v4l.cpp (814) requestBuffers VIDEOIO(V4L2:/dev/video0): failed VIDIOC_REQBUFS: errno=16 (Device or resource busy)\n",
      "[ WARN:0@386.662] global /io/opencv/modules/videoio/src/cap_v4l.cpp (814) requestBuffers VIDEOIO(V4L2:/dev/video0): failed VIDIOC_REQBUFS: errno=16 (Device or resource busy)\n",
      "[ WARN:0@386.662] global /io/opencv/modules/videoio/src/cap_v4l.cpp (814) requestBuffers VIDEOIO(V4L2:/dev/video0): failed VIDIOC_REQBUFS: errno=16 (Device or resource busy)\n",
      "[ WARN:0@386.662] global /io/opencv/modules/videoio/src/cap_v4l.cpp (814) requestBuffers VIDEOIO(V4L2:/dev/video0): failed VIDIOC_REQBUFS: errno=16 (Device or resource busy)\n",
      "[ WARN:0@386.662] global /io/opencv/modules/videoio/src/cap_v4l.cpp (789) requestBuffers VIDEOIO(V4L2:/dev/video0): Insufficient buffer memory\n",
      "[ WARN:0@386.662] global /io/opencv/modules/videoio/src/cap_v4l.cpp (902) open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting video stream...\n"
     ]
    }
   ],
   "source": [
    "# ->\n",
    "# initialise video streamer\n",
    "vs = VideoStream(src=0).start()\n",
    "print(\"starting video stream...\")\n",
    "time.sleep(2.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a528049-0e19-444a-8931-423a28421bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Class(id=2, score=0.62890625)]\n",
      "[Class(id=2, score=0.62890625)]\n",
      "[Class(id=2, score=0.62890625)]\n",
      "[Class(id=2, score=0.8359375)]\n",
      "[Class(id=2, score=0.62890625)]\n",
      "[Class(id=2, score=0.6328125)]\n",
      "[Class(id=2, score=0.62890625)]\n",
      "[Class(id=2, score=0.62890625)]\n",
      "[Class(id=2, score=0.7421875)]\n",
      "[Class(id=2, score=0.89453125)]\n",
      "[Class(id=2, score=0.640625)]\n",
      "[Class(id=2, score=0.63671875)]\n",
      "[Class(id=2, score=0.63671875)]\n",
      "[Class(id=7, score=0.48828125)]\n",
      "[Class(id=7, score=0.6328125)]\n",
      "[Class(id=7, score=0.4609375)]\n",
      "[Class(id=2, score=0.88671875)]\n",
      "[Class(id=2, score=0.93359375)]\n",
      "[Class(id=2, score=0.93359375)]\n",
      "[Class(id=2, score=0.93359375)]\n",
      "[Class(id=2, score=0.93359375)]\n",
      "[Class(id=2, score=0.96484375)]\n",
      "[Class(id=7, score=0.703125)]\n",
      "[Class(id=4, score=0.59375)]\n",
      "[Class(id=7, score=0.328125)]\n",
      "[Class(id=4, score=0.84765625)]\n",
      "[Class(id=6, score=0.86328125)]\n",
      "[Class(id=7, score=0.75390625)]\n",
      "[Class(id=4, score=0.61328125)]\n",
      "[Class(id=4, score=0.69921875)]\n",
      "[Class(id=4, score=0.69140625)]\n",
      "[Class(id=4, score=0.58984375)]\n",
      "[Class(id=4, score=0.80078125)]\n",
      "[Class(id=4, score=0.83203125)]\n",
      "[Class(id=4, score=0.6640625)]\n",
      "[Class(id=2, score=0.78515625)]\n",
      "[Class(id=2, score=0.94140625)]\n",
      "[Class(id=2, score=0.953125)]\n",
      "[Class(id=2, score=0.921875)]\n",
      "[Class(id=2, score=0.921875)]\n",
      "[Class(id=2, score=0.88671875)]\n",
      "[Class(id=2, score=0.921875)]\n",
      "[Class(id=2, score=0.953125)]\n",
      "[Class(id=2, score=0.93359375)]\n",
      "[Class(id=2, score=0.953125)]\n",
      "[Class(id=7, score=0.9921875)]\n",
      "[Class(id=7, score=0.49609375)]\n",
      "[Class(id=4, score=0.6328125)]\n",
      "[Class(id=4, score=0.73828125)]\n",
      "[Class(id=4, score=0.6171875)]\n",
      "[Class(id=4, score=0.8359375)]\n",
      "[Class(id=7, score=0.6015625)]\n",
      "[Class(id=7, score=0.515625)]\n",
      "[Class(id=4, score=0.75)]\n",
      "[Class(id=4, score=0.61328125)]\n",
      "[Class(id=7, score=0.99609375)]\n",
      "[Class(id=7, score=0.98046875)]\n",
      "[Class(id=7, score=0.6015625)]\n",
      "[Class(id=7, score=0.57421875)]\n",
      "[Class(id=7, score=0.90234375)]\n",
      "[Class(id=7, score=0.56640625)]\n",
      "[Class(id=4, score=0.8359375)]\n",
      "[Class(id=7, score=0.67578125)]\n",
      "[Class(id=7, score=0.73046875)]\n",
      "[Class(id=7, score=0.73828125)]\n",
      "[Class(id=7, score=0.69921875)]\n",
      "[Class(id=7, score=0.3828125)]\n",
      "[Class(id=7, score=0.80859375)]\n",
      "[Class(id=4, score=0.65625)]\n",
      "[Class(id=0, score=0.98046875)]\n",
      "[Class(id=4, score=0.98828125)]\n",
      "[Class(id=4, score=0.99609375)]\n",
      "[Class(id=6, score=0.9453125)]\n",
      "[Class(id=7, score=0.62890625)]\n",
      "[Class(id=6, score=0.5703125)]\n",
      "[Class(id=4, score=0.96484375)]\n",
      "[Class(id=7, score=0.53125)]\n",
      "[Class(id=6, score=0.59375)]\n",
      "[Class(id=4, score=0.80859375)]\n",
      "[Class(id=4, score=0.52734375)]\n",
      "[Class(id=4, score=0.96484375)]\n",
      "[Class(id=7, score=0.75390625)]\n",
      "[Class(id=7, score=0.96484375)]\n",
      "[Class(id=7, score=0.96484375)]\n",
      "[Class(id=7, score=0.95703125)]\n",
      "[Class(id=7, score=0.95703125)]\n",
      "[Class(id=7, score=0.96875)]\n",
      "[Class(id=4, score=0.99609375)]\n",
      "[Class(id=7, score=0.7265625)]\n",
      "[Class(id=7, score=0.640625)]\n",
      "[Class(id=7, score=0.94140625)]\n",
      "[Class(id=4, score=0.99609375)]\n",
      "[Class(id=4, score=0.99609375)]\n",
      "[Class(id=4, score=0.99609375)]\n",
      "[Class(id=4, score=0.99609375)]\n",
      "[Class(id=4, score=0.99609375)]\n",
      "[Class(id=4, score=0.99609375)]\n",
      "[Class(id=4, score=0.99609375)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5529/620381231.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#     if key == ord(\"q\"):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#         break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# looping over frames\n",
    "while True:\n",
    "    # take the frame from the threaded video stream and resize to maximum width of 500 pixels\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=500)\n",
    "    orig = frame.copy()\n",
    "    \n",
    "    # prepare the frame for classification by converting it from\n",
    "    # BGR to RGB channel ordering and then from a NumPy array to PIL image format\n",
    "    frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "    # frame image preprocessing\n",
    "    frame_img = Image.fromarray(frame)\n",
    "    frame_arr = np.array(frame_img.convert('L').resize(size, Image.ANTIALIAS))\n",
    "    # broadcasting frame_img to fit dimentions (28, 28, 1)\n",
    "    #frame_arr = frame_arr.reshape((28,28,1))\n",
    "    common.set_input(interpreter, frame_arr)\n",
    "    \n",
    "    # execute inference\n",
    "    interpreter.invoke()\n",
    "    classes = classify.get_classes(interpreter, top_k=1)\n",
    "    # print result\n",
    "    print(classes)\n",
    "#     # show the output frame and wait for a key press\n",
    "#     cv.imshow(\"Frame\", orig)\n",
    "#     key = cv.waitKey(1) & 0xFF\n",
    "\n",
    "#     # if the `q` key was pressed, break from the loop\n",
    "#     if key == ord(\"q\"):\n",
    "#         break\n",
    "    time.sleep(1)\n",
    "    \n",
    "cv.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12578acc-6c13-4aba-91bd-d60cb0280991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ->\n",
    "# Model must be uint8 quantized\n",
    "if common.input_details(interpreter, 'dtype') != np.uint8:\n",
    "    raise ValueError('Only support uint8 input type.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fcfaad8-1bd4-498a-99d8-381e0de38a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing image\n",
    "try: \n",
    "    img  = Image.open(image_file) \n",
    "    img.show()\n",
    "except IOError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5b7ddc98-2253-4732-9510-2de61f3d18d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Resize the image\n",
    "size = common.input_size(interpreter)\n",
    "print(size)\n",
    "image = Image.open(image_file).convert('RGB').resize(size, Image.ANTIALIAS)\n",
    "img_array = np.array(Image.open(image_file).convert('RGB').resize(size, Image.ANTIALIAS))\n",
    "#print(image.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3020d07-07ba-43ab-8935-42391ff892a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ->\n",
    "# resizing with greyscale\n",
    "size = common.input_size(interpreter)\n",
    "#image = Image.open(image_file).convert('L').resize(size, Image.ANTIALIAS)\n",
    "img_array = np.array(Image.open(image_file).convert('L').resize(size, Image.ANTIALIAS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e29627c8-ec0c-453d-b54f-14b2b9f22061",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4093/2412998961.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# getting image size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1_img.GIF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# getting image size \n",
    "im = cv.imread('1_img.GIF')\n",
    "print(im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38926374-7c1a-4755-8a46-5bd4fc11eaf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4549/560130873.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# broadcasting array\n",
    "#image = np.array(np.zeros((28, 28)), np.ones((28,1))) + image\n",
    "a = np.zeros((28,28,1))\n",
    "\n",
    "for row in range(0,27):\n",
    "    for col in range(0,27):\n",
    "        a[row][col][0] = img_array[row][col]\n",
    "\n",
    "print(a)\n",
    "#print(img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79a44271-b7b8-4ced-b468-9b015d76c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ->\n",
    "# first broadcasting img_array to fit dimentions (28, 28, 1)\n",
    "img_array = img_array.reshape((28,28,1))\n",
    "common.set_input(interpreter, img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "859942cb-b80c-40ad-a408-d53b66cd12cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default parameters for manual input processing\n",
    "top_k = 1\n",
    "threshold = 0.0\n",
    "count = 1\n",
    "input_mean = 128.0\n",
    "input_std = 128.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6079d5ba-c873-4b20-aa17-657fb5a9a0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scales': array([1.], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}\n",
      "image preprocessed\n"
     ]
    }
   ],
   "source": [
    "# Manual image preprocessing - 2 transfomrations: normalization and quantization\n",
    "# combined in 1 line: q = (input - mean) / (std * scale) + zero_point\n",
    "# 1e-5 used instead of 0 to prevent division by 0 error\n",
    "params = common.input_details(interpreter, 'quantization_parameters')\n",
    "print(params)\n",
    "scale = params['scales']\n",
    "zero_point = params['zero_points']\n",
    "\n",
    "# default parameters used\n",
    "mean = input_mean\n",
    "std = input_std\n",
    "\n",
    "if abs(scale * std - 1) < 1e-5 and abs(mean - zero_point) < 1e-5:\n",
    "    # Input data does not require preprocessing.\n",
    "    print('no preprocessing required')\n",
    "    common.set_input(interpreter, image)\n",
    "else:\n",
    "    # Input data requires preprocessing\n",
    "    print('image preprocessed')\n",
    "    img_array = img_array.reshape((28,28,1))\n",
    "    normalized_input = (img_array - mean) / (std * scale) + zero_point\n",
    "    np.clip(normalized_input, 0, 255, out=normalized_input)\n",
    "    common.set_input(interpreter, normalized_input.astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72ef95e1-df9b-4717-bfd4-b616fe781e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Class(id=2, score=0.859375)]\n"
     ]
    }
   ],
   "source": [
    "# ->\n",
    "# Run an inference\n",
    "#common.set_input(interpreter, img_array)\n",
    "interpreter.invoke()\n",
    "classes = classify.get_classes(interpreter, top_k=1)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33a13716-937e-44c7-bb92-c67e9105a38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class | score\n",
      "2     | 0.85938\n"
     ]
    }
   ],
   "source": [
    "# Print the result\n",
    "labels = dataset.read_label_file(label_file)\n",
    "print(\"class | score\")\n",
    "for c in classes:\n",
    "    print('%s     | %.5f' % (labels.get(c.id, c.id), c.score))\n",
    "    #print(c.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df0a18-0a98-4eb3-9b23-4e3d82a309b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aa4f22-a793-4b8a-808f-bf0336bc42ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
