{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Converting the Handwriting Recogn. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is first built and trained on the original dataset - MNIST dataset. The link is given below. <br>\n",
    "The saved model is then converted to tflite with post-integer quanitzation. <br>\n",
    "The EdgeTPU requires a fully qantized model with 8 bit integer data for input/output tensors, activations etc.<br> <br>\n",
    "This file can be executed on a Windows/MacOS or Linux PC. The .tflite model file is then to be transferred to <br> \n",
    "EdgeTPU for inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "### Importing the neccessary libaries and the data set\n",
    "[NIST, hand written digit data set](https://www.tensorflow.org/datasets/catalog/mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "raw_mimetype": "pdf",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import time, os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image, ImageOps\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "\n",
    "os.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"]=\"4\"\n",
    "logdir=os.getcwd()+'/logs';\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1,write_graph=True, write_images=True,profile_batch = '500,520')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving the training dataset\n",
    "For information on the data set see here [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(img_train, label_train), (img_test, label_test) = tfds.as_numpy(tfds.load('mnist',split=['train', 'test'],batch_size=-1,as_supervised=True,try_gcs=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of used data sets 60.000 = all\n",
    "number_of_used_ds = 60000\n",
    "# Number of classes; 0 to 9\n",
    "num_classes = 10\n",
    "\n",
    "scale.fit(img_train[0:number_of_used_ds].reshape(-1,784))\n",
    "\n",
    "X_train_sc = scale.transform(img_train[0:number_of_used_ds,:,:,0].reshape(-1,28*28))\n",
    "X_test_sc = scale.transform(img_test.reshape(-1,28*28))\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(label_train[0:number_of_used_ds],10)\n",
    "y_test = tf.keras.utils.to_categorical(label_test,10)\n",
    "\n",
    "# Show an example picture\n",
    "imshow(X_train_sc[1,].reshape(28,28),cmap='gray')\n",
    "print(y_train[0:10,],X_train_sc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a neural network\n",
    "Two experiments:\n",
    "\n",
    "1. create a neuronal network only with fully connected layers, no convolutional layers, use 2 hidden layers with 50 neurons; **change the variable network to 'flatten'**\n",
    "2. now create a convolutional neuronal network with the following layers (**change the variable network to 'conv2d'**):\n",
    "|Layer (type)                 |  # filter / size  |\n",
    "|-----------------------------|-------------------|\n",
    "|conv2d (Conv2D)              |  20 (3,3)         |\n",
    "|max_pooling2d (MaxPooling2D) |  - (2,2)          |\n",
    "|conv2d_1 (Conv2D)            |  10 (3,3)         |\n",
    "|max_pooling2d_1 (MaxPooling2 |  - (2,2)          |\n",
    "|flatten (Flatten)            |  -                |\n",
    "|dropout (Dropout)            |  -                |\n",
    "|dense (Dense)                |  num_classes      |\n",
    "\n",
    "Use the documentation available from here: [https://keras.io/api/layers/](https://keras.io/api/layers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = 'conv2d'\n",
    "if network == 'conv2d':\n",
    "    X_train=np.expand_dims((X_train_sc.reshape(-1,28,28)), -1)\n",
    "    X_test=np.expand_dims((X_test_sc.reshape(-1,28,28)), -1)    \n",
    "    input_shape = (28,28,1)\n",
    "else: \n",
    "    X_train = X_train_sc\n",
    "    X_test = X_test_sc\n",
    "    input_shape = (28*28,)\n",
    "#\n",
    "model = keras.Sequential([\n",
    "        keras.Input(shape=input_shape),\n",
    "#-------------------------------------------------------------\n",
    "        #layers.Dense(50, activation='relu',name='first_hidden'),\n",
    "        #layers.Dense(50, activation='relu',name='second_hidden'),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "#-------------------------------------------------------------\n",
    "        layers.Dense(num_classes, activation=\"softmax\",name='output'),])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\" ,metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, batch_size=200, epochs=5)\n",
    "print(\"Duration %.2f \" % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Score on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test[0:200,], y_test[0:200,], verbose=0)\n",
    "print(\"Test accuracy: %.2f %%\" % (score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(model, 'saved_model')\n",
    "\n",
    "# an alternative, usually for keras model:\n",
    "#model.save('path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the below code if you want to load the model, not required here\n",
    "model = load_model('saved_model')\n",
    "# loading keras model:\n",
    "#model = keras.models.load_model('path/to/location')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing it with own hand written digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('../test.png').convert(\"L\")\n",
    "imshow(ImageOps.invert(img),cmap='gray')\n",
    "test = scale.transform(np.array(ImageOps.invert(img).resize((28,28))).reshape(1,-1))\n",
    "if network == 'conv2d':\n",
    "    test = test.reshape(1,28,28,1)\n",
    "else: \n",
    "    test = test.reshape(1,28*28)\n",
    "#\n",
    "# Predicting the Test set results\n",
    "for i in range(0,num_classes):\n",
    "   print(\"Detected a %.0f with %.2f %% \" % (i,model.predict(test).reshape(-1,1)[i]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Representative Dataset for Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting and broadcasting the training dataset to match the model input size\n",
    "img_train = img_train.reshape(img_train.shape[0], 28, 28, 1)\n",
    "tf.cast(img_train, tf.float32)\n",
    "print(img_train.shape)\n",
    "\n",
    "# creating representative dataset generator function to quantize the model variables optimally\n",
    "def representative_data_gen():\n",
    "    # take 1 batch only of a portion of the dataset\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(img_train).batch(1).take(100):\n",
    "        yield [tf.cast(input_value, tf.float32)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the Converter and Converting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building converter using the saved model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('saved_model/')\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.allow_custom_ops = True\n",
    "\n",
    "# Ensuring that if any ops can't be quantized, the converter throws an error\n",
    "#converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Setting the input and output tensors to uint8\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant = converter.convert()\n",
    "print('conversion successful')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code block contains some variations for converting the model (commented out). <br>\n",
    "These variations are useful in cases of errors in conversion from the above code block. <br>\n",
    "Typically the above code should work for most of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some variations in convereter code for different models (commented out)\n",
    "#converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "#converter.allow_custom_ops = True\n",
    "#converter._experimental_new_quantizer = True\n",
    "\n",
    "# freezing the input tensor for quantization\n",
    "#imp_model = tf.saved_model.load('<path>')\n",
    "#concrete_func = imp_model.signatures[\"serving_default\"]\n",
    "#concrete_func.inputs[0].set_shape(<shape>)\n",
    "#converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func], imp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Converted Tflite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as .tflite file\n",
    "with open('handwriting_model_quant.tflite', 'wb') as f:\n",
    "  f.write(tflite_model_quant)\n",
    "print('model saved successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Netron <link> https://netron.app/ </link> can be used to visualize the quantized model: Load the model file into the app and it will show the entire model graph for easier analysis. <br> If the model is successfully quantized, you will see two 'quantize' blocks one after the input and the other before the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantized tflite model has to be compiled by the edgetpu compiler to run on the Edge TPU. <br>\n",
    "The compiler can be downloaded on a linux system and the below code line can be executed with this link <link>https://coral.ai/docs/edgetpu/compiler/#system-requirements</link> <br>\n",
    "For non-linux based system, use the Colab here <link>https://colab.research.google.com/github/google-coral/tutorials/blob/master/compile_for_edgetpu.ipynb</link> <br>\n",
    "A file with the same name but ending with 'edgetpu.tflite' will be created. <br> Transfer this file to Edge TPU for inferencing.\n",
    "\n",
    "Alternatively, open the notebook on Edge TPU itself run the below line. Further explanation can be found in document 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "!edgetpu_compiler -s handwriting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: It is very important to check the result of compilation or the log to verify whether all the operations (or most) are mapped to Edge TPU or not. <br> Operations which are not mapped to Edge TPU will run on the CPU leading to a decline in performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
